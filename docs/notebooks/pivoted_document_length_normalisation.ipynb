{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "from gensim.sklearn_api.tfidf import TfIdfTransformer\n",
    "from gensim.matutils import corpus2csc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats=['sci.space', 'comp.graphics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',\n",
    "                                categories=['sci.space', 'comp.graphics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_len(x, corpus=True):\n",
    "    if corpus:\n",
    "        length = 0\n",
    "        for i in x:\n",
    "            length += len(i)\n",
    "        return length\n",
    "    else:\n",
    "        return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9728813559322034\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, random_state=49)\n",
    "\n",
    "id2word = Dictionary([_.split() for _ in X_train])\n",
    "\n",
    "train_corpus = [id2word.doc2bow(i.split()) for i in X_train]\n",
    "test_corpus = [id2word.doc2bow(i.split()) for i in X_test]\n",
    "\n",
    "tfidf_transformer = TfIdfTransformer(pivot_norm=True, slope=0.6).fit(train_corpus)\n",
    "X_train_tfidf = corpus2csc(tfidf_transformer.transform(train_corpus), num_terms=len(id2word)).T\n",
    "X_test_tfidf = corpus2csc(tfidf_transformer.transform(test_corpus), num_terms=len(id2word)).T\n",
    "clf = LogisticRegression().fit(X_train_tfidf, y_train)\n",
    "print clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_scores = clf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gettopk(doc_scores, X_test, k=None):\n",
    "    if k is None:\n",
    "        k = len(X_test)/10\n",
    "    doc_scores = sorted(enumerate(doc_scores), key=lambda x: x[1])\n",
    "    leng=0\n",
    "    kleng=0\n",
    "    for i,_ in enumerate(doc_scores):\n",
    "        leng+=len(X_test[_[0]])\n",
    "        if i==k:\n",
    "           kleng=leng \n",
    "    print \"top\",k ,\"documents have mean length of\",kleng/k\n",
    "    print \"corpus has a mean length of\",leng/float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 29 documents have mean length of 1432\n",
      "corpus has a mean length of 1686.73898305\n"
     ]
    }
   ],
   "source": [
    "print (\"With pivoted normalisation our top k docs have mean lenght closer to the global mean doc length\")\n",
    "gettopk(doc_scores, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9661016949152542\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, random_state=49)\n",
    "\n",
    "id2word = Dictionary([_.split() for _ in X_train])\n",
    "\n",
    "train_corpus = [id2word.doc2bow(i.split()) for i in X_train]\n",
    "test_corpus = [id2word.doc2bow(i.split()) for i in X_test]\n",
    "\n",
    "tfidf_transformer = TfIdfTransformer(pivot_norm=True, slope=1).fit(train_corpus)\n",
    "X_train_tfidf = corpus2csc(tfidf_transformer.transform(train_corpus), num_terms=len(id2word)).T\n",
    "X_test_tfidf = corpus2csc(tfidf_transformer.transform(test_corpus), num_terms=len(id2word)).T\n",
    "clf = LogisticRegression().fit(X_train_tfidf, y_train)\n",
    "print clf.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_scores = clf.decision_function(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 29 documents have mean length of 910\n",
      "corpus has a mean length of 1686.73898305\n"
     ]
    }
   ],
   "source": [
    "print (\"Normal cosine normalisation favors short documents as our top k docs have a smaller mean\")\n",
    "gettopk(doc_scores, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
